{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47bee5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query\n",
      "temperature\n",
      "document12 is the most relevant document\n",
      "ranking of the documents\n",
      "document12 rank is 1\n",
      "document10 rank is 2\n",
      "document72 rank is 3\n",
      "document183 rank is 4\n"
     ]
    }
   ],
   "source": [
    "# implementation of vector space model for document retrieval\n",
    "\n",
    "from xml.dom.minidom import Document\n",
    "import pandas\n",
    "# module to read the contents of the file from a csv file\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "# module to redirect the output to a text file\n",
    "\n",
    "import math\n",
    "# module to perform mathematical functions\n",
    "\n",
    "terms = []\n",
    "# list to store the terms present in the documents\n",
    "\n",
    "keys = []\n",
    "# list to store the names of the documents\n",
    "\n",
    "vec_Dic = {}\n",
    "# dictionary to store the name of the document and the weight as list\n",
    "\n",
    "dicti = {}\n",
    "# dictionary to store the name of the document and the terms present in it as a\n",
    "# vector\n",
    "\n",
    "dummy_List = []\n",
    "# list for performing some operations and clearing them\n",
    "\n",
    "term_Freq = {}\n",
    "# dictionary to store the term and the number of times of its occurrence in the\n",
    "# documents\n",
    "\n",
    "idf = {}\n",
    "# dictionary to store the term and the inverse document frequency\n",
    "\n",
    "weight = {}\n",
    "# dictionary to store the term and the weight which is the product of term\n",
    "# frequency and inverse document frequency\n",
    "\n",
    "\n",
    "def filter(documents, rows, cols):\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # traversal through the data frame\n",
    "\n",
    "            if(j == 0):\n",
    "                # first column has the name of the document in the csv file\n",
    "                keys.append(documents.loc[i].iat[j])\n",
    "            else:\n",
    "                dummy_List.append(documents.loc[i].iat[j])\n",
    "                # dummy list to update the terms in the dictionary\n",
    "\n",
    "                if documents.loc[i].iat[j] not in terms:\n",
    "                    # add the terms to the list if it is not present else continue\n",
    "                    terms.append(documents.loc[i].iat[j])\n",
    "\n",
    "        copy = dummy_List.copy()\n",
    "        # copying the the dummy list to a different list\n",
    "\n",
    "        dicti.update({documents.loc[i].iat[0]: copy})\n",
    "        # adding the key value pair to a dictionary\n",
    "\n",
    "        dummy_List.clear()\n",
    "        # clearing the dummy list\n",
    "\n",
    "\n",
    "def compute_Weight(doc_Count, cols):\n",
    "    '''Function to compute the weight for each of the terms in the document.\n",
    "    Here the weight is calculated with the help of term frequency and\n",
    "    inverse document frequency'''\n",
    "\n",
    "    for i in terms:\n",
    "        # initially adding all the elements into the dictionary and initialising\n",
    "        # the values as zero\n",
    "        if i not in term_Freq:\n",
    "            term_Freq.update({i: 0})\n",
    "\n",
    "    for key, value in dicti.items():\n",
    "        # to get the number of occurrence of each terms\n",
    "        for k in value:\n",
    "            if k in term_Freq:\n",
    "                term_Freq[k] += 1\n",
    "                # value incremented by one if the term is found in the documents\n",
    "\n",
    "    idf = term_Freq.copy()\n",
    "    # copying the term frequency dictionary to a dictionary named idf which is\n",
    "    # further neede for computation\n",
    "\n",
    "    for i in term_Freq:\n",
    "        term_Freq[i] = term_Freq[i]/cols\n",
    "        # term frequency is number of occurrence divided by total number of\n",
    "        # documents\n",
    "\n",
    "    for i in idf:\n",
    "        if idf[i] != doc_Count:\n",
    "            idf[i] = math.log2(cols / idf[i])\n",
    "            # inverse document frequency log of total number of documents divided\n",
    "            # by number of occurrence of the terms\n",
    "        else:\n",
    "            idf[i] = 0\n",
    "            # this is to avoid the zero division error\n",
    "\n",
    "    for i in idf:\n",
    "        weight.update({i: idf[i]*term_Freq[i]})\n",
    "        # weight is the product of term frequency and the inverse document\n",
    "        # frequency\n",
    "\n",
    "    for i in dicti:\n",
    "        for j in dicti[i]:\n",
    "            dummy_List.append(weight[j])\n",
    "\n",
    "        copy = dummy_List.copy()\n",
    "        vec_Dic.update({i: copy})\n",
    "        dummy_List.clear()\n",
    "        # above operations performed to get the dictionary of weighted vector\n",
    "        # for each of the documents\n",
    "\n",
    "\n",
    "def get_Weight_For_Query(query):\n",
    "    '''function to get the weight for each terms present in the query, here we\n",
    "    consider the term frequency as the weight of the terms'''\n",
    "\n",
    "    query_Freq = {}\n",
    "    # initialisation of the dictionary with query terms as key and its weight as\n",
    "    # the values\n",
    "\n",
    "    for i in terms:\n",
    "        # initially adding all the elements into the dictionary and initialising\n",
    "        # the values as zero\n",
    "        if i not in query_Freq:\n",
    "            query_Freq.update({i: 0})\n",
    "\n",
    "    for val in query:\n",
    "        # to get the number of occurrence of each terms\n",
    "        if val in query_Freq:\n",
    "            query_Freq[val] += 1\n",
    "            # value incremented by one if the term is found in the documents\n",
    "\n",
    "    for i in query_Freq:\n",
    "        query_Freq[i] = query_Freq[i] / len(query)\n",
    "        # term frequency obtained by dividing the number of occurrence of terms by\n",
    "        # total number of terms in the query\n",
    "\n",
    "    return query_Freq\n",
    "    # return the dictionary in which the key is the term and the value is the\n",
    "    # weight\n",
    "\n",
    "\n",
    "def similarity_Computation(query_Weight):\n",
    "    ''' Function to calculate the similarity measure in which the weight of the\n",
    "    query and the document is multiplied in the numerator and the the weight is\n",
    "    squared and squareroot is taken the weights of the query and document'''\n",
    "\n",
    "    numerator = 0\n",
    "    denomi1 = 0\n",
    "    denomi2 = 0\n",
    "    # initialisation of the variables with zero which is needed for computation\n",
    "\n",
    "    similarity = {}\n",
    "    # initialisation of dictionary which has the name of document as key and the\n",
    "    # similarity measure as value\n",
    "\n",
    "    for document in dicti:\n",
    "        for terms in dicti[document]:\n",
    "            # cosine similarity is calculated\n",
    "\n",
    "            numerator += weight[terms] * query_Weight[terms]\n",
    "            denomi1 += weight[terms] * weight[terms]\n",
    "            denomi2 += query_Weight[terms] * query_Weight[terms]\n",
    "            # the summation values of the weight is calculated and later they are\n",
    "            # divided\n",
    "\n",
    "        if denomi1 != 0 and denomi2 != 0:\n",
    "            # to avoid the zero division error\n",
    "\n",
    "            simi = numerator / (math.sqrt(denomi1) * math.sqrt(denomi2))\n",
    "            similarity.update({document: simi})\n",
    "            #dictionary is updated\n",
    "\n",
    "            numerator = 0\n",
    "            denomi2 = 0\n",
    "            denomi1 = 0\n",
    "            # reinitialisation of the variables to zero\n",
    "\n",
    "    return (similarity)\n",
    "    # the dictionary containing similarity measure as the value\n",
    "\n",
    "\n",
    "def prediction(similarity, doc_count):\n",
    "    '''Function to predict the document which is relevant to the query '''\n",
    "    # print(\"bbvbvbvbvpainb\",similarity.get)\n",
    "    # with open('output.txt', 'w') as f:\n",
    "    # \twith redirect_stdout(f):\n",
    "            # to redirect the output to a text file\n",
    "    if len(similarity)!=0:\t\t\n",
    "        ans = max(similarity, key=similarity.get)\n",
    "        print(ans, \"is the most relevant document\")\n",
    "        print(\"ranking of the documents\")\n",
    "    else:\n",
    "        print(\"Document not found\")\n",
    "    # to print the name of the document which is most relevant\n",
    "\n",
    "\n",
    "    for i in range(doc_count):\n",
    "        # print(\"fdfdfdfdfdfd\",similarity)\n",
    "        if len(similarity)!=0:\n",
    "            ans = max(similarity, key=lambda x: similarity[x])\n",
    "            print(ans, \"rank is\", i+1)\n",
    "        # to print the document name and its rank\n",
    "\n",
    "            similarity.pop(ans)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    documents = pandas.read_excel(r'data.xlsx')\n",
    "    # to read the data from the csv file as a dataframe\n",
    "\n",
    "    rows = len(documents)\n",
    "    # to get the number of rows\n",
    "\n",
    "    cols = len(documents.columns)\n",
    "    # to get the number of columns\n",
    "\n",
    "    filter(documents, rows, cols)\n",
    "    # function call to read and separate the name of the documents and the terms\n",
    "    # present in it to a separate list from the data frame and also create a\n",
    "    # dictionary which has the name of the document as key and the terms present\n",
    "    # in it as the list of strings which is the value of the key\n",
    "\n",
    "    compute_Weight(rows, cols)\n",
    "    # Function to compute the weight for each of the terms in the document.\n",
    "    # Here the weight is calculated with the help of term frequency and inverse\n",
    "    # document frequency\n",
    "\n",
    "    print(\"Enter the query\")\n",
    "    query = input()\n",
    "    # to get the query input from the user, the below input is given for obtaining\n",
    "    # the output as in output.txt file\n",
    "    # one three three\n",
    "\n",
    "    query = query.split(' ')\n",
    "    # spliting the query as a list of strings\n",
    "\n",
    "    query_Weight = get_Weight_For_Query(query)\n",
    "    # function call to get the weight for each terms present in the query, here we\n",
    "    # consider the term frequency as the weight of the terms'''\n",
    "\n",
    "    similarity = similarity_Computation(query_Weight)\n",
    "    # Function call to calculate the similarity measure in which the weight of the\n",
    "    # query and the document is multiplied in the numerator and the weight is\n",
    "    # squared and squareroot is taken the weights of the query and document\n",
    "\n",
    "    prediction(similarity, rows)\n",
    "    # Function call to predict the document which is relevant to the query\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e52ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
