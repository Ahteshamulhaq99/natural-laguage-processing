{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47bee5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query\n",
      "document12 is the most relevant document\n",
      "ranking of the documents\n",
      "document12 rank is 1\n",
      "document183 rank is 2\n",
      "document72 rank is 3\n",
      "document10 rank is 4\n",
      "document64 rank is 5\n",
      "document178 rank is 6\n",
      "document48 rank is 7\n",
      "document156 rank is 8\n"
     ]
    }
   ],
   "source": [
    "# implementation of vector space model for document retrieval\n",
    "\n",
    "from xml.dom.minidom import Document\n",
    "import pandas\n",
    "# module to read the contents of the file from a csv file\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "# module to redirect the output to a text file\n",
    "\n",
    "import math\n",
    "# module to perform mathematical functions\n",
    "\n",
    "terms = []\n",
    "# list to store the terms present in the documents\n",
    "\n",
    "keys = []\n",
    "# list to store the names of the documents\n",
    "\n",
    "vec_Dic = {}\n",
    "# dictionary to store the name of the document and the weight as list\n",
    "\n",
    "dicti = {}\n",
    "# dictionary to store the name of the document and the terms present in it as a\n",
    "# vector\n",
    "\n",
    "dummy_List = []\n",
    "# list for performing some operations and clearing them\n",
    "\n",
    "term_Freq = {}\n",
    "# dictionary to store the term and the number of times of its occurrence in the\n",
    "# documents\n",
    "\n",
    "idf = {}\n",
    "# dictionary to store the term and the inverse document frequency\n",
    "\n",
    "weight = {}\n",
    "# dictionary to store the term and the weight which is the product of term\n",
    "# frequency and inverse document frequency\n",
    "\n",
    "\n",
    "def filter(documents, rows, cols):\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # traversal through the data frame\n",
    "\n",
    "            if(j == 0):\n",
    "                # first column has the name of the document in the csv file\n",
    "                keys.append(documents.loc[i].iat[j])\n",
    "            else:\n",
    "                dummy_List.append(documents.loc[i].iat[j])\n",
    "                # dummy list to update the terms in the dictionary\n",
    "\n",
    "                if documents.loc[i].iat[j] not in terms:\n",
    "                    # add the terms to the list if it is not present else continue\n",
    "                    terms.append(documents.loc[i].iat[j])\n",
    "\n",
    "        copy = dummy_List.copy()\n",
    "        # copying the the dummy list to a different list\n",
    "\n",
    "        dicti.update({documents.loc[i].iat[0]: copy})\n",
    "        # adding the key value pair to a dictionary\n",
    "\n",
    "        dummy_List.clear()\n",
    "        # clearing the dummy list\n",
    "\n",
    "\n",
    "def compute_Weight(doc_Count, cols):\n",
    "    for i in terms:\n",
    "        # initially adding all the elements into the dictionary and initialising\n",
    "        # the values as zero\n",
    "        if i not in term_Freq:\n",
    "            term_Freq.update({i: 0})\n",
    "\n",
    "    for key, value in dicti.items():\n",
    "        # to get the number of occurrence of each terms\n",
    "        for k in value:\n",
    "            if k in term_Freq:\n",
    "                term_Freq[k] += 1\n",
    "                # value incremented by one if the term is found in the documents\n",
    "\n",
    "    idf = term_Freq.copy()\n",
    "    for i in term_Freq:\n",
    "        term_Freq[i] = term_Freq[i]/cols\n",
    "        # term frequency is number of occurrence divided by total number of\n",
    "        # documents\n",
    "\n",
    "    for i in idf:\n",
    "        if idf[i] != doc_Count:\n",
    "            idf[i] = math.log2(cols / idf[i])\n",
    "            # inverse document frequency log of total number of documents divided\n",
    "            # by number of occurrence of the terms\n",
    "        else:\n",
    "            idf[i] = 0\n",
    "            # this is to avoid the zero division error\n",
    "\n",
    "    for i in idf:\n",
    "        weight.update({i: idf[i]*term_Freq[i]})\n",
    "        # weight is the product of term frequency and the inverse document\n",
    "        # frequency\n",
    "\n",
    "    for i in dicti:\n",
    "        for j in dicti[i]:\n",
    "            dummy_List.append(weight[j])\n",
    "\n",
    "        copy = dummy_List.copy()\n",
    "        vec_Dic.update({i: copy})\n",
    "        dummy_List.clear()\n",
    "        # above operations performed to get the dictionary of weighted vector\n",
    "        # for each of the documents\n",
    "\n",
    "\n",
    "def get_Weight_For_Query(query):\n",
    "    '''function to get the weight for each terms present in the query, here we\n",
    "    consider the term frequency as the weight of the terms'''\n",
    "\n",
    "    query_Freq = {}\n",
    "    for i in terms:\n",
    "        if i not in query_Freq:\n",
    "            query_Freq.update({i: 0})\n",
    "\n",
    "    for val in query:\n",
    "        # to get the number of occurrence of each terms\n",
    "        if val in query_Freq:\n",
    "            query_Freq[val] += 1\n",
    "            # value incremented by one if the term is found in the documents\n",
    "\n",
    "    for i in query_Freq:\n",
    "        query_Freq[i] = query_Freq[i] / len(query)\n",
    "\n",
    "    return query_Freq\n",
    "def similarity_Computation(query_Weight):\n",
    "    numerator = 0\n",
    "    denomi1 = 0\n",
    "    denomi2 = 0\n",
    "    similarity = {}\n",
    "    for document in dicti:\n",
    "        for terms in dicti[document]:\n",
    "            # cosine similarity is calculated\n",
    "\n",
    "            numerator += weight[terms] * query_Weight[terms]\n",
    "            denomi1 += weight[terms] * weight[terms]\n",
    "            denomi2 += query_Weight[terms] * query_Weight[terms]\n",
    "            # the summation values of the weight is calculated and later they are\n",
    "            # divided\n",
    "\n",
    "        if denomi1 != 0 and denomi2 != 0:\n",
    "            # to avoid the zero division error\n",
    "\n",
    "            simi = numerator / (math.sqrt(denomi1) * math.sqrt(denomi2))\n",
    "            similarity.update({document: simi})\n",
    "            #dictionary is updated\n",
    "\n",
    "            numerator = 0\n",
    "            denomi2 = 0\n",
    "            denomi1 = 0\n",
    "            # reinitialisation of the variables to zero\n",
    "\n",
    "    return (similarity)\n",
    "def prediction(similarity, doc_count):\n",
    "    '''Function to predict the document which is relevant to the query '''\n",
    "    if len(similarity)!=0:\n",
    "        ans = max(similarity, key=similarity.get)\n",
    "        print(ans, \"is the most relevant document\")\n",
    "        print(\"ranking of the documents\")\n",
    "    else:\n",
    "        print(\"Document not found\")\n",
    "    for i in range(doc_count):\n",
    "        if len(similarity)!=0:\n",
    "            ans = max(similarity, key=lambda x: similarity[x])\n",
    "            print(ans, \"rank is\", i+1)\n",
    "        # to print the document name and its rank\n",
    "            similarity.pop(ans)\n",
    "def main():\n",
    "    documents = pandas.read_excel(r'data.xlsx')\n",
    "    rows = len(documents)\n",
    "    cols = len(documents.columns)\n",
    "    filter(documents, rows, cols)\n",
    "    compute_Weight(rows, cols)\n",
    "    print(\"Enter the query\")\n",
    "    query = input()\n",
    "    query = query.split(' ')\n",
    "    query_Weight = get_Weight_For_Query(query)\n",
    "    similarity = similarity_Computation(query_Weight)\n",
    "    prediction(similarity, rows)\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e52ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "24b8e48887c830b049cf7a9bfe070c74445bfe406cbd20f9629aa02b26f0d3e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
